{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e61a3f03",
   "metadata": {},
   "source": [
    "# Workflow as Agent with Reflection and Retry Pattern\n",
    "\n",
    "**Copyright (c) Microsoft. All rights reserved.**\n",
    "\n",
    "## Purpose\n",
    "\n",
    "This notebook demonstrates how to wrap a workflow as an agent using `WorkflowAgent`. It uses a reflection pattern where:\n",
    "\n",
    "- A **Worker** executor generates responses\n",
    "- A **Reviewer** executor evaluates them\n",
    "- If the response is not approved, the Worker regenerates based on feedback\n",
    "- Only approved responses are emitted to the external consumer\n",
    "- The workflow completes when idle\n",
    "\n",
    "## Key Concepts Demonstrated\n",
    "\n",
    "1. **WorkflowAgent**: Wraps a workflow to behave like a regular agent\n",
    "2. **Cyclic workflow design**: Worker ↔ Reviewer for iterative improvement\n",
    "3. **AgentRunUpdateEvent**: Mechanism for emitting approved responses externally\n",
    "4. **Structured output parsing**: Review feedback using Pydantic\n",
    "5. **State management**: Pending requests and retry logic\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "- OpenAI account configured and accessible for `OpenAIChatClient`\n",
    "- Familiarity with `WorkflowBuilder`, `Executor`, `WorkflowContext`, and event handling\n",
    "- Understanding of how agent messages are generated, reviewed, and re-submitted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c864d041",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "Import required libraries for workflow orchestration, agent framework, and structured data handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed244286",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from uuid import uuid4\n",
    "\n",
    "from agent_framework import (\n",
    "    AgentRunResponseUpdate,\n",
    "    AgentRunUpdateEvent,\n",
    "    ChatClientProtocol,\n",
    "    ChatMessage,\n",
    "    Contents,\n",
    "    Executor,\n",
    "    Role,\n",
    "    WorkflowBuilder,\n",
    "    WorkflowContext,\n",
    "    handler,\n",
    ")\n",
    "from agent_framework.openai import OpenAIChatClient\n",
    "from pydantic import BaseModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c4a0d5",
   "metadata": {},
   "source": [
    "## Define Data Structures\n",
    "\n",
    "Create structured request and response classes for communication between Worker and Reviewer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0da3d618",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class ReviewRequest:\n",
    "    \"\"\"Structured request passed from Worker to Reviewer for evaluation.\"\"\"\n",
    "\n",
    "    request_id: str\n",
    "    user_messages: list[ChatMessage]\n",
    "    agent_messages: list[ChatMessage]\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ReviewResponse:\n",
    "    \"\"\"Structured response from Reviewer back to Worker.\"\"\"\n",
    "\n",
    "    request_id: str\n",
    "    feedback: str\n",
    "    approved: bool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3c76e0",
   "metadata": {},
   "source": [
    "## Implement Reviewer Executor\n",
    "\n",
    "The Reviewer evaluates agent responses against quality criteria:\n",
    "- **Relevance**: Response addresses the query\n",
    "- **Accuracy**: Information is correct\n",
    "- **Clarity**: Response is easy to understand\n",
    "- **Completeness**: Response covers all aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fe88cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reviewer(Executor):\n",
    "    \"\"\"Executor that reviews agent responses and provides structured feedback.\"\"\"\n",
    "\n",
    "    def __init__(self, id: str, chat_client: ChatClientProtocol) -> None:\n",
    "        super().__init__(id=id)\n",
    "        self._chat_client = chat_client\n",
    "\n",
    "    @handler\n",
    "    async def review(self, request: ReviewRequest, ctx: WorkflowContext[ReviewResponse]) -> None:\n",
    "        print(f\"Reviewer: Evaluating response for request {request.request_id[:8]}...\")\n",
    "\n",
    "        # Define structured schema for the LLM to return.\n",
    "        class _Response(BaseModel):\n",
    "            feedback: str\n",
    "            approved: bool\n",
    "\n",
    "        # Construct review instructions and context.\n",
    "        messages = [\n",
    "            ChatMessage(\n",
    "                role=Role.SYSTEM,\n",
    "                text=(\n",
    "                    \"You are a reviewer for an AI agent. Provide feedback on the \"\n",
    "                    \"exchange between a user and the agent. Indicate approval only if:\\n\"\n",
    "                    \"- Relevance: response addresses the query\\n\"\n",
    "                    \"- Accuracy: information is correct\\n\"\n",
    "                    \"- Clarity: response is easy to understand\\n\"\n",
    "                    \"- Completeness: response covers all aspects\\n\"\n",
    "                    \"Do not approve until all criteria are satisfied.\"\n",
    "                ),\n",
    "            )\n",
    "        ]\n",
    "        # Add conversation history.\n",
    "        messages.extend(request.user_messages)\n",
    "        messages.extend(request.agent_messages)\n",
    "\n",
    "        # Add explicit review instruction.\n",
    "        messages.append(ChatMessage(role=Role.USER, text=\"Please review the agent's responses.\"))\n",
    "\n",
    "        print(\"Reviewer: Sending review request to LLM...\")\n",
    "        response = await self._chat_client.get_response(\n",
    "            messages=messages, response_format=_Response\n",
    "        )\n",
    "\n",
    "        parsed = _Response.model_validate_json(response.messages[-1].text)\n",
    "\n",
    "        print(f\"Reviewer: Review complete - Approved: {parsed.approved}\")\n",
    "        print(f\"Reviewer: Feedback: {parsed.feedback}\")\n",
    "\n",
    "        # Send structured review result to Worker.\n",
    "        await ctx.send_message(\n",
    "            ReviewResponse(\n",
    "                request_id=request.request_id, feedback=parsed.feedback, approved=parsed.approved\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e060559",
   "metadata": {},
   "source": [
    "## Implement Worker Executor\n",
    "\n",
    "The Worker generates responses and incorporates feedback when necessary. It maintains state for pending requests to handle the retry cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2f400533",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Worker(Executor):\n",
    "    \"\"\"Executor that generates responses and incorporates feedback when necessary.\"\"\"\n",
    "\n",
    "    def __init__(self, id: str, chat_client: ChatClientProtocol) -> None:\n",
    "        super().__init__(id=id)\n",
    "        self._chat_client = chat_client\n",
    "        self._pending_requests: dict[str, tuple[ReviewRequest, list[ChatMessage]]] = {}\n",
    "\n",
    "    @handler\n",
    "    async def handle_user_messages(\n",
    "        self, user_messages: list[ChatMessage], ctx: WorkflowContext[ReviewRequest]\n",
    "    ) -> None:\n",
    "        print(\"Worker: Received user messages, generating response...\")\n",
    "\n",
    "        # Initialize chat with system prompt.\n",
    "        messages = [ChatMessage(role=Role.SYSTEM, text=\"You are a helpful assistant.\")]\n",
    "        messages.extend(user_messages)\n",
    "\n",
    "        print(\"Worker: Calling LLM to generate response...\")\n",
    "        response = await self._chat_client.get_response(messages=messages)\n",
    "        print(f\"Worker: Response generated: {response.messages[-1].text}\")\n",
    "\n",
    "        # Add agent messages to context.\n",
    "        messages.extend(response.messages)\n",
    "\n",
    "        # Create review request and send to Reviewer.\n",
    "        request = ReviewRequest(\n",
    "            request_id=str(uuid4()), user_messages=user_messages, agent_messages=response.messages\n",
    "        )\n",
    "        print(f\"Worker: Sending response for review (ID: {request.request_id[:8]})\")\n",
    "        await ctx.send_message(request)\n",
    "\n",
    "        # Track request for possible retry.\n",
    "        self._pending_requests[request.request_id] = (request, messages)\n",
    "\n",
    "    @handler\n",
    "    async def handle_review_response(\n",
    "        self, review: ReviewResponse, ctx: WorkflowContext[ReviewRequest]\n",
    "    ) -> None:\n",
    "        print(\n",
    "            print(\n",
    "                f\"Worker: Received review for request {review.request_id[:8]} - \"\n",
    "                f\"Approved: {review.approved}\"\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if review.request_id not in self._pending_requests:\n",
    "            raise ValueError(f\"Unknown request ID in review: {review.request_id}\")\n",
    "\n",
    "        request, messages = self._pending_requests.pop(review.request_id)\n",
    "\n",
    "        if review.approved:\n",
    "            print(\"Worker: Response approved. Emitting to external consumer...\")\n",
    "            contents: list[Contents] = []\n",
    "            for message in request.agent_messages:\n",
    "                contents.extend(message.contents)\n",
    "\n",
    "            # Emit approved result to external consumer via AgentRunUpdateEvent.\n",
    "            await ctx.add_event(\n",
    "                AgentRunUpdateEvent(\n",
    "                    self.id, data=AgentRunResponseUpdate(contents=contents, role=Role.ASSISTANT)\n",
    "                )\n",
    "            )\n",
    "            return\n",
    "\n",
    "        print(f\"Worker: Response not approved. Feedback: {review.feedback}\")\n",
    "        print(\"Worker: Regenerating response with feedback...\")\n",
    "\n",
    "        # Incorporate review feedback.\n",
    "        messages.append(ChatMessage(role=Role.SYSTEM, text=review.feedback))\n",
    "        messages.append(\n",
    "            ChatMessage(\n",
    "                role=Role.SYSTEM,\n",
    "                text=\"Please incorporate the feedback and regenerate the response.\",\n",
    "            )\n",
    "        )\n",
    "        messages.extend(request.user_messages)\n",
    "\n",
    "        # Retry with updated prompt.\n",
    "        response = await self._chat_client.get_response(messages=messages)\n",
    "        print(f\"Worker: New response generated: {response.messages[-1].text}\")\n",
    "\n",
    "        messages.extend(response.messages)\n",
    "\n",
    "        # Send updated request for re-review.\n",
    "        new_request = ReviewRequest(\n",
    "            request_id=review.request_id,\n",
    "            user_messages=request.user_messages,\n",
    "            agent_messages=response.messages,\n",
    "        )\n",
    "        await ctx.send_message(new_request)\n",
    "\n",
    "        # Track new request for further evaluation.\n",
    "        self._pending_requests[new_request.request_id] = (new_request, messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a3d7c2",
   "metadata": {},
   "source": [
    "## Build and Run the Workflow Agent\n",
    "\n",
    "Create the cyclic workflow (Worker ↔ Reviewer) and wrap it as an agent. The workflow will iteratively improve responses until the Reviewer approves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38a5c253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Workflow Agent Demo\n",
      "==================================================\n",
      "Creating chat client and executors...\n",
      "Building workflow with Worker ↔ Reviewer cycle...\n",
      "Running workflow agent with user query...\n",
      "Query: 'Write code for parallel reading 1 million files on disk and write to a sorted output file.'\n",
      "--------------------------------------------------\n",
      "Worker: Received user messages, generating response...\n",
      "Worker: Calling LLM to generate response...\n",
      "Worker: Response generated: Certainly! Reading 1 million files in parallel and writing their contents to a sorted output file requires efficient handling of concurrency, I/O, and sorting. Here's a Python example using `concurrent.futures` for parallelism and `heapq.merge` for efficient merging of sorted data:\n",
      "\n",
      "### Assumptions:\n",
      "- Each file contains sorted data lines.\n",
      "- You want to produce a single sorted output file containing all lines.\n",
      "- Files are large but can be processed line-by-line.\n",
      "- You have sufficient memory and resources for parallel processing.\n",
      "\n",
      "### Approach:\n",
      "1. Read all files in parallel asynchronously.\n",
      "2. Collect iterators for each file to avoid loading everything into memory.\n",
      "3. Use `heapq.merge()` to merge sorted iterators efficiently.\n",
      "4. Write the merged output to a file.\n",
      "\n",
      "---\n",
      "\n",
      "### Example Python Code:\n",
      "\n",
      "```python\n",
      "import os\n",
      "import glob\n",
      "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
      "import heapq\n",
      "\n",
      "# Path to your files directory\n",
      "FILES_DIR = '/path/to/files'\n",
      "FILE_PATTERN = '*.txt'  # Adjust depending on your files' extension\n",
      "OUTPUT_FILE = 'merged_sorted_output.txt'\n",
      "\n",
      "def read_file_lines(filepath):\n",
      "    \"\"\"Generator to read lines from a file.\"\"\"\n",
      "    with open(filepath, 'r', encoding='utf-8') as f:\n",
      "        for line in f:\n",
      "            yield line.rstrip('\\n')  # Remove trailing newline\n",
      "\n",
      "def process_file(filepath):\n",
      "    \"\"\"Returns an iterator of lines in the file.\"\"\"\n",
      "    return read_file_lines(filepath)\n",
      "\n",
      "def main():\n",
      "    # Gather all file paths\n",
      "    file_paths = glob.glob(os.path.join(FILES_DIR, FILE_PATTERN))\n",
      "    \n",
      "    # Use ThreadPoolExecutor for I/O-bound tasks\n",
      "    with ThreadPoolExecutor(max_workers=20) as executor:\n",
      "        # Submit file reading tasks\n",
      "        future_to_path = {executor.submit(process_file, fp): fp for fp in file_paths}\n",
      "        \n",
      "        # As each file is processed, get its iterator\n",
      "        # Store generators in a list for merging\n",
      "        iterators = []\n",
      "        for future in as_completed(future_to_path):\n",
      "            fp = future_to_path[future]\n",
      "            try:\n",
      "                iterator = future.result()\n",
      "                iterators.append(iterator)\n",
      "            except Exception as e:\n",
      "                print(f\"Error reading {fp}: {e}\")\n",
      "    \n",
      "    # Merge all sorted iterators\n",
      "    with open(OUTPUT_FILE, 'w', encoding='utf-8') as out_file:\n",
      "        for line in heapq.merge(*iterators):\n",
      "            out_file.write(line + '\\n')\n",
      "\n",
      "    print(f\"Merge complete. Output saved to {OUTPUT_FILE}\")\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### Notes:\n",
      "- **Parallelism**: Adjust `max_workers` depending on your CPU and I/O capacity.\n",
      "- **Memory**: This approach uses iterators and `heapq.merge`, which is memory-efficient for sorted streams.\n",
      "- **Sorting Within Files**: This assumes each file is already sorted. If not, you'll need to sort each file individually first.\n",
      "- **Error Handling**: Basic error handling included; you can expand as needed.\n",
      "- **Scaling**: For extremely large datasets or files, consider more advanced solutions like distributed processing frameworks (e.g., Spark).\n",
      "\n",
      "---\n",
      "\n",
      "### Additional Tips:\n",
      "- To handle unsorted files, you can sort each file first:\n",
      "  ```python\n",
      "  def sort_file(filepath):\n",
      "      with open(filepath, 'r', encoding='utf-8') as f:\n",
      "          lines = f.readlines()\n",
      "      lines.sort()\n",
      "      sorted_filepath = filepath + '_sorted'\n",
      "      with open(sorted_filepath, 'w', encoding='utf-8') as f:\n",
      "          f.writelines(lines)\n",
      "      return sorted_filepath\n",
      "  ```\n",
      "- For processing unsorted files, incorporate sorting before merging.\n",
      "\n",
      "---\n",
      "\n",
      "Feel free to ask for customization or further assistance!\n",
      "Worker: Sending response for review (ID: 9afd6121)\n",
      "Reviewer: Evaluating response for request 9afd6121...\n",
      "Reviewer: Sending review request to LLM...\n",
      "Reviewer: Review complete - Approved: True\n",
      "Reviewer: Feedback: Relevance: The agent's response is relevant, directly addressing the task of reading 1 million files in parallel and producing a sorted output file.\n",
      "\n",
      "Accuracy: The explanation of using Python's concurrent.futures for parallelism and heapq.merge for sorted merging is accurate. The code correctly implements parallel reading, accumulates iterators, and merges them into a sorted output. The explanations about memory and I/O-bound tasks are correct. Error handling is acknowledged and the approach to sorting unsorted files is sound.\n",
      "\n",
      "Clarity: The answer is well-structured with clear sectioning: assumptions, approach, code, notes, and additional tips. The code is commented and separated into logical blocks, making it easy to understand.\n",
      "\n",
      "Completeness: The response covers all aspects: parallel file reading, memory-conscious merging, file sorting (if needed), error handling, scalability notes, and customization tips. The solution anticipates potential issues (file sorting and scale) and provides suggestions for each.\n",
      "\n",
      "Conclusion: Approved. The answer fulfills all criteria for relevance, accuracy, clarity, and completeness.\n",
      "Worker: Received review for request 9afd6121 - Approved: True\n",
      "None\n",
      "Worker: Response approved. Emitting to external consumer...\n",
      "Agent Response: Certainly! Reading 1 million files in parallel and writing their contents to a sorted output file requires efficient handling of concurrency, I/O, and sorting. Here's a Python example using `concurrent.futures` for parallelism and `heapq.merge` for efficient merging of sorted data:\n",
      "\n",
      "### Assumptions:\n",
      "- Each file contains sorted data lines.\n",
      "- You want to produce a single sorted output file containing all lines.\n",
      "- Files are large but can be processed line-by-line.\n",
      "- You have sufficient memory and resources for parallel processing.\n",
      "\n",
      "### Approach:\n",
      "1. Read all files in parallel asynchronously.\n",
      "2. Collect iterators for each file to avoid loading everything into memory.\n",
      "3. Use `heapq.merge()` to merge sorted iterators efficiently.\n",
      "4. Write the merged output to a file.\n",
      "\n",
      "---\n",
      "\n",
      "### Example Python Code:\n",
      "\n",
      "```python\n",
      "import os\n",
      "import glob\n",
      "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
      "import heapq\n",
      "\n",
      "# Path to your files directory\n",
      "FILES_DIR = '/path/to/files'\n",
      "FILE_PATTERN = '*.txt'  # Adjust depending on your files' extension\n",
      "OUTPUT_FILE = 'merged_sorted_output.txt'\n",
      "\n",
      "def read_file_lines(filepath):\n",
      "    \"\"\"Generator to read lines from a file.\"\"\"\n",
      "    with open(filepath, 'r', encoding='utf-8') as f:\n",
      "        for line in f:\n",
      "            yield line.rstrip('\\n')  # Remove trailing newline\n",
      "\n",
      "def process_file(filepath):\n",
      "    \"\"\"Returns an iterator of lines in the file.\"\"\"\n",
      "    return read_file_lines(filepath)\n",
      "\n",
      "def main():\n",
      "    # Gather all file paths\n",
      "    file_paths = glob.glob(os.path.join(FILES_DIR, FILE_PATTERN))\n",
      "    \n",
      "    # Use ThreadPoolExecutor for I/O-bound tasks\n",
      "    with ThreadPoolExecutor(max_workers=20) as executor:\n",
      "        # Submit file reading tasks\n",
      "        future_to_path = {executor.submit(process_file, fp): fp for fp in file_paths}\n",
      "        \n",
      "        # As each file is processed, get its iterator\n",
      "        # Store generators in a list for merging\n",
      "        iterators = []\n",
      "        for future in as_completed(future_to_path):\n",
      "            fp = future_to_path[future]\n",
      "            try:\n",
      "                iterator = future.result()\n",
      "                iterators.append(iterator)\n",
      "            except Exception as e:\n",
      "                print(f\"Error reading {fp}: {e}\")\n",
      "    \n",
      "    # Merge all sorted iterators\n",
      "    with open(OUTPUT_FILE, 'w', encoding='utf-8') as out_file:\n",
      "        for line in heapq.merge(*iterators):\n",
      "            out_file.write(line + '\\n')\n",
      "\n",
      "    print(f\"Merge complete. Output saved to {OUTPUT_FILE}\")\n",
      "\n",
      "if __name__ == \"__main__\":\n",
      "    main()\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "### Notes:\n",
      "- **Parallelism**: Adjust `max_workers` depending on your CPU and I/O capacity.\n",
      "- **Memory**: This approach uses iterators and `heapq.merge`, which is memory-efficient for sorted streams.\n",
      "- **Sorting Within Files**: This assumes each file is already sorted. If not, you'll need to sort each file individually first.\n",
      "- **Error Handling**: Basic error handling included; you can expand as needed.\n",
      "- **Scaling**: For extremely large datasets or files, consider more advanced solutions like distributed processing frameworks (e.g., Spark).\n",
      "\n",
      "---\n",
      "\n",
      "### Additional Tips:\n",
      "- To handle unsorted files, you can sort each file first:\n",
      "  ```python\n",
      "  def sort_file(filepath):\n",
      "      with open(filepath, 'r', encoding='utf-8') as f:\n",
      "          lines = f.readlines()\n",
      "      lines.sort()\n",
      "      sorted_filepath = filepath + '_sorted'\n",
      "      with open(sorted_filepath, 'w', encoding='utf-8') as f:\n",
      "          f.writelines(lines)\n",
      "      return sorted_filepath\n",
      "  ```\n",
      "- For processing unsorted files, incorporate sorting before merging.\n",
      "\n",
      "---\n",
      "\n",
      "Feel free to ask for customization or further assistance!\n",
      "==================================================\n",
      "Workflow completed!\n"
     ]
    }
   ],
   "source": [
    "async def run_workflow_agent():\n",
    "    print(\"Starting Workflow Agent Demo\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    # Initialize chat clients and executors.\n",
    "    print(\"Creating chat client and executors...\")\n",
    "    mini_chat_client = OpenAIChatClient(model_id=\"gpt-4.1-nano\")\n",
    "    chat_client = OpenAIChatClient(model_id=\"gpt-4.1\")\n",
    "    reviewer = Reviewer(id=\"reviewer\", chat_client=chat_client)\n",
    "    worker = Worker(id=\"worker\", chat_client=mini_chat_client)\n",
    "\n",
    "    print(\"Building workflow with Worker ↔ Reviewer cycle...\")\n",
    "    agent = (\n",
    "        WorkflowBuilder()\n",
    "        .add_edge(worker, reviewer)  # Worker sends responses to Reviewer\n",
    "        .add_edge(reviewer, worker)  # Reviewer provides feedback to Worker\n",
    "        .set_start_executor(worker)\n",
    "        .build()\n",
    "        .as_agent()  # Wrap workflow as an agent\n",
    "    )\n",
    "\n",
    "    print(\"Running workflow agent with user query...\")\n",
    "    query = (\n",
    "        \"Write code for parallel reading 1 million files on disk and write to a sorted output file.\"\n",
    "    )\n",
    "    print(f\"Query: '{query}'\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Run agent in streaming mode to observe incremental updates.\n",
    "    async for event in agent.run_stream(query):\n",
    "        print(f\"Agent Response: {event}\")\n",
    "\n",
    "    print(\"=\" * 50)\n",
    "    print(\"Workflow completed!\")\n",
    "\n",
    "\n",
    "# Run the workflow agent\n",
    "await run_workflow_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed6ec23e",
   "metadata": {},
   "source": [
    "## Try Different Queries\n",
    "\n",
    "Experiment with different types of queries to see how the reflection pattern works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d26048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def test_query(query: str):\n",
    "    \"\"\"Test the workflow agent with a specific query.\"\"\"\n",
    "    print(f\"\\nTesting Query: {query}\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    mini_chat_client = OpenAIChatClient(model_id=\"gpt-4.1-nano\")\n",
    "    chat_client = OpenAIChatClient(model_id=\"gpt-4.1\")\n",
    "    reviewer = Reviewer(id=\"reviewer\", chat_client=chat_client)\n",
    "    worker = Worker(id=\"worker\", chat_client=mini_chat_client)\n",
    "\n",
    "    agent = (\n",
    "        WorkflowBuilder()\n",
    "        .add_edge(worker, reviewer)\n",
    "        .add_edge(reviewer, worker)\n",
    "        .set_start_executor(worker)\n",
    "        .build()\n",
    "        .as_agent()\n",
    "    )\n",
    "\n",
    "    async for event in agent.run_stream(query):\n",
    "        print(f\"Response: {event}\")\n",
    "\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "\n",
    "# Test with different query types\n",
    "await test_query(\"Explain quantum computing in simple terms.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897dabdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a coding question\n",
    "await test_query(\"Write a Python function to find the longest palindrome substring.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bc06540",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a complex analysis question\n",
    "await test_query(\"Compare and contrast microservices and monolithic architectures.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078235f2",
   "metadata": {},
   "source": [
    "## Workflow Architecture Visualization\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────────┐\n",
    "│                    Workflow as Agent                        │\n",
    "│                                                             │\n",
    "│  ┌─────────┐         ┌──────────┐         ┌──────────┐   │\n",
    "│  │  User   │────────▶│  Worker  │────────▶│ Reviewer │   │\n",
    "│  │  Query  │         │          │         │          │   │\n",
    "│  └─────────┘         └──────────┘         └──────────┘   │\n",
    "│                            ▲                     │         │\n",
    "│                            │   Not Approved      │         │\n",
    "│                            │   (with feedback)   │         │\n",
    "│                            └─────────────────────┘         │\n",
    "│                                                             │\n",
    "│                      Approved ──────────▶ External         │\n",
    "│                                          Consumer          │\n",
    "└─────────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Flow:\n",
    "1. User query enters the workflow\n",
    "2. Worker generates initial response\n",
    "3. Reviewer evaluates against quality criteria\n",
    "4. If not approved: feedback sent to Worker → regenerate\n",
    "5. If approved: response emitted to external consumer\n",
    "6. Workflow completes when idle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608afecc",
   "metadata": {},
   "source": [
    "## Advanced: Custom Review Criteria\n",
    "\n",
    "Modify the Reviewer's criteria to focus on specific aspects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732746ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrictCodeReviewer(Executor):\n",
    "    \"\"\"Reviewer with strict criteria for code-related responses.\"\"\"\n",
    "\n",
    "    def __init__(self, id: str, chat_client: ChatClientProtocol) -> None:\n",
    "        super().__init__(id=id)\n",
    "        self._chat_client = chat_client\n",
    "\n",
    "    @handler\n",
    "    async def review(self, request: ReviewRequest, ctx: WorkflowContext[ReviewResponse]) -> None:\n",
    "        print(f\"StrictCodeReviewer: Evaluating response for request {request.request_id[:8]}...\")\n",
    "\n",
    "        class _Response(BaseModel):\n",
    "            feedback: str\n",
    "            approved: bool\n",
    "\n",
    "        messages = [\n",
    "            ChatMessage(\n",
    "                role=Role.SYSTEM,\n",
    "                text=(\n",
    "                    \"You are a strict code reviewer. Approve only if:\\n\"\n",
    "                    \"- Code is syntactically correct\\n\"\n",
    "                    \"- Includes error handling\\n\"\n",
    "                    \"- Has proper type hints\\n\"\n",
    "                    \"- Includes docstrings\\n\"\n",
    "                    \"- Follows best practices (e.g., async/await for I/O)\\n\"\n",
    "                    \"- Includes usage example\"\n",
    "                ),\n",
    "            )\n",
    "        ]\n",
    "        messages.extend(request.user_messages)\n",
    "        messages.extend(request.agent_messages)\n",
    "        messages.append(ChatMessage(role=Role.USER, text=\"Please review the code response.\"))\n",
    "\n",
    "        response = await self._chat_client.get_response(\n",
    "            messages=messages, response_format=_Response\n",
    "        )\n",
    "        parsed = _Response.model_validate_json(response.messages[-1].text)\n",
    "\n",
    "        print(f\"StrictCodeReviewer: Approved: {parsed.approved}\")\n",
    "        print(f\"StrictCodeReviewer: Feedback: {parsed.feedback}\")\n",
    "\n",
    "        await ctx.send_message(\n",
    "            ReviewResponse(\n",
    "                request_id=request.request_id, feedback=parsed.feedback, approved=parsed.approved\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "# Test with strict code reviewer\n",
    "async def test_strict_code_review():\n",
    "    mini_chat_client = OpenAIChatClient(model_id=\"gpt-4.1-nano\")\n",
    "    chat_client = OpenAIChatClient(model_id=\"gpt-4.1\")\n",
    "    reviewer = StrictCodeReviewer(id=\"strict_reviewer\", chat_client=chat_client)\n",
    "    worker = Worker(id=\"worker\", chat_client=mini_chat_client)\n",
    "\n",
    "    agent = (\n",
    "        WorkflowBuilder()\n",
    "        .add_edge(worker, reviewer)\n",
    "        .add_edge(reviewer, worker)\n",
    "        .set_start_executor(worker)\n",
    "        .build()\n",
    "        .as_agent()\n",
    "    )\n",
    "\n",
    "    async for event in agent.run_stream(\"Write a function to read a JSON file asynchronously.\"):\n",
    "        print(f\"Response: {event}\")\n",
    "\n",
    "\n",
    "await test_strict_code_review()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdaa09f4",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Workflow as Agent Pattern**: Using `WorkflowBuilder.build().as_agent()` to expose workflows as agents\n",
    "2. **Cyclic Workflows**: Worker ↔ Reviewer pattern for iterative refinement\n",
    "3. **Structured Communication**: Using dataclasses and Pydantic for type-safe messaging\n",
    "4. **State Management**: Tracking pending requests for retry logic\n",
    "5. **Event Emission**: Using `AgentRunUpdateEvent` to emit approved responses\n",
    "6. **Quality Control**: Multi-criteria evaluation before accepting responses\n",
    "\n",
    "### Key Takeaways\n",
    "\n",
    "- Workflows can behave like agents using `.as_agent()`\n",
    "- Cyclic workflows enable self-improvement patterns\n",
    "- Structured outputs ensure reliable inter-executor communication\n",
    "- Review criteria can be customized per use case\n",
    "- External consumers only see approved, high-quality responses\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Add multiple reviewers for different aspects (code quality, security, performance)\n",
    "- Implement retry limits to prevent infinite loops\n",
    "- Add metrics tracking (review iterations, approval rate)\n",
    "- Integrate with AgenticFleet for multi-agent orchestration\n",
    "- Add human-in-the-loop approval for sensitive operations"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-fleet (3.13.2)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
