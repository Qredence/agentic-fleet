"""Minimal FastAPI server exposing placeholder endpoints for the frontend."""

from __future__ import annotations

import asyncio
import builtins
import json
import logging
import threading
import time
from collections.abc import AsyncGenerator
from contextlib import asynccontextmanager
from json import JSONDecodeError
from typing import Any
from uuid import uuid4

from agent_framework.exceptions import ServiceInitializationError, ServiceResponseException
from agent_framework.openai import OpenAIResponsesClient
from fastapi import Depends, FastAPI, Request, Response, WebSocket, WebSocketDisconnect, status
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse, StreamingResponse
from pydantic import BaseModel
from sqlalchemy.orm import Session

from agenticfleet import __version__
from agenticfleet.api.event_collector import EventCollector
from agenticfleet.api.event_translator import EventTranslator
from agenticfleet.api.models.chat_models import (
    ChatRequest,
    ChatResponse,
    ExecutionState,
    ExecutionStatus,
)
from agenticfleet.api.redis_client import RedisClient
from agenticfleet.api.websocket_manager import ConnectionManager
from agenticfleet.api.workflow_factory import WorkflowFactory
from agenticfleet.persistance.database import ApprovalRequest, ApprovalStatus, get_db, init_db


class ApprovalResponse(BaseModel):
    decision: str


# Initialize workflow factory
_workflow_factory: WorkflowFactory | None = None
_redis_client: RedisClient | None = None
_websocket_manager: ConnectionManager | None = None


def get_workflow_factory() -> WorkflowFactory:
    """Get or create the workflow factory singleton."""
    global _workflow_factory
    if _workflow_factory is None:
        _workflow_factory = WorkflowFactory()
    return _workflow_factory


def get_redis_client() -> RedisClient:
    """Get the Redis client singleton."""
    global _redis_client
    if _redis_client is None:
        raise RuntimeError("Redis client not initialized")
    return _redis_client


def get_websocket_manager() -> ConnectionManager:
    """Get the WebSocket manager singleton."""
    global _websocket_manager
    if _websocket_manager is None:
        _websocket_manager = ConnectionManager()
    return _websocket_manager


# Initialize event translator
_event_translator = EventTranslator()
PLACEHOLDER_DETAIL = {
    "detail": (
        "This endpoint is not implemented in the minimal AgenticFleet distribution. "
        "Restore the full backend to enable interactive features."
    )
}


class InMemoryConversationStore:
    """Simple in-memory conversation storage compatible with frontend expectations."""

    def __init__(self) -> None:
        self._conversations: dict[str, dict[str, Any]] = {}
        self._items: dict[str, list[dict[str, Any]]] = {}
        self._lock = threading.Lock()
        self._next_id = 1

    @staticmethod
    def _clone_item(item: dict[str, Any]) -> dict[str, Any]:
        return {
            **item,
            "content": [block.copy() for block in item.get("content", [])],
        }

    def _generate_id(self) -> str:
        conversation_id = f"conv-{self._next_id:06d}"
        self._next_id += 1
        return conversation_id

    @staticmethod
    def _sanitize_metadata(metadata: dict[str, Any] | None) -> dict[str, str]:
        if not isinstance(metadata, dict):
            return {}

        sanitized: dict[str, str] = {}
        for key, value in metadata.items():
            if not isinstance(key, str):
                key = str(key)
            if value is None:
                sanitized[key] = ""
            elif isinstance(value, str):
                sanitized[key] = value
            else:
                sanitized[key] = str(value)
        return sanitized

    @staticmethod
    def _now() -> int:
        return int(time.time())

    @staticmethod
    def _clone(record: dict[str, Any]) -> dict[str, Any]:
        return {**record, "metadata": {**record.get("metadata", {})}}

    def create(self, metadata: dict[str, Any] | None = None) -> dict[str, Any]:
        sanitized_metadata = self._sanitize_metadata(metadata)
        conversation_id = self._generate_id()
        timestamp = self._now()
        record = {
            "id": conversation_id,
            "created_at": timestamp,
            "updated_at": timestamp,
            "metadata": sanitized_metadata,
        }

        with self._lock:
            self._conversations[conversation_id] = record
            self._items[conversation_id] = []

        return self._clone(record)

    def add_message(
        self,
        conversation_id: str,
        role: str,
        content: list[dict[str, Any]] | None = None,
    ) -> dict[str, Any]:
        sanitized_content: list[dict[str, Any]] = []
        if isinstance(content, list):
            for block in content:
                if isinstance(block, dict):
                    sanitized_content.append(block.copy())
                else:
                    sanitized_content.append({"type": "text", "text": str(block)})

        item = {
            "id": f"item-{uuid4().hex[:12]}",
            "role": role,
            "content": sanitized_content,
            "created_at": self._now(),
        }

        with self._lock:
            conversation = self._conversations.get(conversation_id)
            if conversation is None:
                raise KeyError(conversation_id)
            conversation["updated_at"] = item["created_at"]
            self._items.setdefault(conversation_id, []).append(item)

        return self._clone_item(item)

    def list(self) -> list[dict[str, Any]]:
        with self._lock:
            records = [self._clone(record) for record in self._conversations.values()]

        return sorted(records, key=lambda record: record["updated_at"], reverse=True)

    def get(self, conversation_id: str) -> dict[str, Any] | None:
        with self._lock:
            record = self._conversations.get(conversation_id)
            if record is None:
                return None
            return self._clone(record)

    def delete(self, conversation_id: str) -> bool:
        with self._lock:
            conversation_removed = self._conversations.pop(conversation_id, None)
            self._items.pop(conversation_id, None)
        return conversation_removed is not None

    def list_items(self, conversation_id: str) -> builtins.list[dict[str, Any]] | None:
        with self._lock:
            if conversation_id not in self._conversations:
                return None
            items = self._items.get(conversation_id, [])
            return [self._clone_item(item) for item in items]


LOGGER = logging.getLogger(__name__)

DEFAULT_RESPONSES_MODEL = "gpt-5-mini"
ASSISTANT_INSTRUCTION = (
    "You are the AgenticFleet assistant. Provide concise, accurate updates about the "
    "multi-agent orchestration system, highlighting how the manager coordinates the "
    "researcher, coder, and reviewer agents with dynamic spawning and human-in-the-loop approvals."
)
FALLBACK_SUMMARY = (
    "AgenticFleet is a multi-agent orchestration framework that unites a planning manager with "
    "specialist researcher, coder, and reviewer agents. It supports dynamic agent spawning, "
    "human-in-the-loop approvals, checkpointing, and detailed observability so teams can tackle "
    "complex tasks reliably."
)


def _extract_conversation_id(payload: dict[str, Any]) -> str | None:
    conversation = payload.get("conversation")
    if isinstance(conversation, str) and conversation:
        return conversation
    if isinstance(conversation, dict):
        identifier = conversation.get("id")
        if isinstance(identifier, str) and identifier:
            return identifier
    return None


def _extract_user_text(input_payload: Any) -> str | None:
    if isinstance(input_payload, str):
        return input_payload

    if not isinstance(input_payload, list):
        return None

    collected: list[str] = []
    for item in input_payload:
        if not isinstance(item, dict):
            continue
        if item.get("type") != "message":
            continue
        contents = item.get("content")
        if not isinstance(contents, list):
            continue
        for block in contents:
            if isinstance(block, dict) and block.get("type") == "input_text":
                text = block.get("text")
                if isinstance(text, str):
                    collected.append(text)
    if not collected:
        return None
    return "\n\n".join(collected)


async def _build_assistant_reply(user_text: str | None) -> tuple[str, str, dict[str, int | None]]:
    prompt = (user_text or "Provide a concise overview of AgenticFleet for a new user.").strip()
    request_payload = (
        f"{ASSISTANT_INSTRUCTION}\n\n"
        "Summarise the following request with actionable highlights about AgenticFleet's "
        "architecture, dynamic agent spawning, and human-in-the-loop safeguards."
        f"\n\nRequest:\n{prompt}"
    )

    usage: dict[str, int | None] = {
        "input_tokens": None,
        "output_tokens": None,
        "total_tokens": None,
    }

    try:
        client = OpenAIResponsesClient(model_id=DEFAULT_RESPONSES_MODEL)
        response = await client.get_response(request_payload)
        text = (response.text or "").strip()
        if not text and response.messages:
            text = "\n".join(msg.text for msg in response.messages if getattr(msg, "text", ""))
        if not text:
            text = FALLBACK_SUMMARY

        if response.usage_details:
            usage = {
                "input_tokens": response.usage_details.input_token_count,
                "output_tokens": response.usage_details.output_token_count,
                "total_tokens": response.usage_details.total_token_count,
            }

        return text, response.model_id or DEFAULT_RESPONSES_MODEL, usage
    except (ServiceInitializationError, ServiceResponseException) as exc:
        LOGGER.exception(
            "OpenAI Responses client failed (%s); falling back to static summary",
            exc,
            exc_info=True,
        )
        fallback = FALLBACK_SUMMARY
        if user_text:
            fallback = (
                f"{fallback}\n\nI wasn't able to reach the model for this specific request, but here's a "
                "refresher on AgenticFleet. Your original prompt was: "
                f"{user_text.strip()}"
            )
        return fallback, DEFAULT_RESPONSES_MODEL, usage
    except Exception as exc:  # pragma: no cover - guard for unexpected client errors
        LOGGER.exception("Unexpected error while generating assistant reply", exc_info=True)
        fallback = FALLBACK_SUMMARY
        if user_text:
            fallback = (
                f"{fallback}\n\nWe encountered an unexpected issue while processing your request: {exc}."
                f"\nOriginal prompt: {user_text.strip()}"
            )
        return fallback, DEFAULT_RESPONSES_MODEL, usage


def _format_sse_event(event: dict[str, Any]) -> bytes:
    payload = json.dumps(event, ensure_ascii=False)
    return f"data: {payload}\n\n".encode()


def _not_implemented() -> JSONResponse:
    return JSONResponse(status_code=status.HTTP_501_NOT_IMPLEMENTED, content=PLACEHOLDER_DETAIL)


def create_app() -> FastAPI:
    import os

    @asynccontextmanager
    async def lifespan(app: FastAPI) -> AsyncGenerator[None, None]:
        """Lifespan handler to initialize and clean up resources (DB, Redis).

        Replaces deprecated ``on_event('startup')`` / ``on_event('shutdown')`` handlers.
        """
        global _redis_client

        # Initialize database
        init_db()
        LOGGER.info("Database initialized")

        # Initialize Redis client
        redis_url = os.getenv("REDIS_URL", "redis://localhost:6379")
        _redis_client = RedisClient(redis_url=redis_url, ttl_seconds=3600)
        try:
            await _redis_client.connect()
            LOGGER.info("Redis client connected")
        except Exception as e:
            LOGGER.error(f"Failed to connect to Redis: {e}")
            _redis_client = None

        try:
            yield
        finally:
            if _redis_client:
                try:
                    await _redis_client.disconnect()
                    LOGGER.info("Redis client disconnected")
                except Exception:
                    LOGGER.exception("Error while disconnecting Redis client")

    app = FastAPI(title="AgenticFleet Minimal API", version=__version__, lifespan=lifespan)

    app.add_middleware(
        CORSMiddleware,
        allow_origins=["*"],
        allow_credentials=True,
        allow_methods=["*"],
        allow_headers=["*"],
    )

    @app.get("/")
    async def root() -> dict[str, str]:
        return {"name": "AgenticFleet Minimal API", "version": __version__, "status": "ok"}

    @app.get("/health")
    async def health() -> dict[str, str]:
        return {"status": "ok"}

    @app.get("/api/health")
    async def api_health() -> dict[str, str]:
        return {"status": "ok", "version": __version__}

    @app.get("/api/info")
    async def api_info() -> dict[str, str]:
        return {"name": "AgenticFleet", "version": __version__, "mode": "minimal"}

    # Legacy API surface used by the trimmed frontend ---------------------

    conversation_store = InMemoryConversationStore()

    # Legacy API surface used by the trimmed frontend ---------------------

    @app.api_route("/api/chat", methods=["POST"])
    async def chat_placeholder(_: Request) -> JSONResponse:
        return _not_implemented()

    @app.api_route("/api/chat/stream", methods=["GET"])
    async def chat_stream_placeholder(_: Request) -> JSONResponse:
        return _not_implemented()

    @app.api_route("/api/approval/{request_id}", methods=["POST"])
    async def approval_placeholder(request_id: str, _: Request) -> JSONResponse:
        return _not_implemented()

    @app.api_route("/api/conversations", methods=["GET", "POST"])
    async def conversations_placeholder(_: Request) -> JSONResponse:
        return _not_implemented()

    @app.api_route("/api/conversations/{conversation_id}", methods=["GET", "DELETE"])
    async def conversation_item_placeholder(conversation_id: str, _: Request) -> JSONResponse:
        return _not_implemented()

    @app.api_route("/api/checkpoints", methods=["GET"])
    async def checkpoints_placeholder(_: Request) -> JSONResponse:
        return _not_implemented()

    @app.api_route("/api/checkpoints/{checkpoint_id}/resume", methods=["POST"])
    async def checkpoint_resume_placeholder(checkpoint_id: str, _: Request) -> JSONResponse:
        return _not_implemented()

    @app.api_route("/api/{path:path}", methods=["GET", "POST", "PUT", "PATCH", "DELETE"])
    async def fallback_placeholder(path: str, _: Request) -> JSONResponse:
        return _not_implemented()

    # v1 API surface (Human Approval + Conversations + Entities) ----------

    @app.api_route("/v1/entities", methods=["GET"])
    async def entities_placeholder() -> JSONResponse:
        return _not_implemented()

    @app.api_route("/v1/entities/{entity_id}/info", methods=["GET"])
    async def entity_info_placeholder(entity_id: str) -> JSONResponse:
        return _not_implemented()

    @app.api_route("/v1/conversations", methods=["GET", "POST"])
    async def conversations_v1(request: Request) -> JSONResponse:
        if request.method == "GET":
            return JSONResponse(
                status_code=status.HTTP_200_OK,
                content={"data": conversation_store.list()},
            )

        try:
            payload = await request.json()
        except (JSONDecodeError, ValueError):
            payload = {}

        metadata = payload.get("metadata") if isinstance(payload, dict) else None
        record = conversation_store.create(
            metadata=metadata if isinstance(metadata, dict) else None
        )
        return JSONResponse(status_code=status.HTTP_201_CREATED, content=record)

    @app.api_route("/v1/conversations/{conversation_id}", methods=["GET", "DELETE"])
    async def conversations_v1_item(conversation_id: str, request: Request) -> Response:
        if request.method == "GET":
            record = conversation_store.get(conversation_id)
            if record is None:
                return JSONResponse(
                    status_code=status.HTTP_404_NOT_FOUND,
                    content={"detail": "Conversation not found"},
                )
            return JSONResponse(status_code=status.HTTP_200_OK, content=record)

        deleted = conversation_store.delete(conversation_id)
        if not deleted:
            return JSONResponse(
                status_code=status.HTTP_404_NOT_FOUND,
                content={"detail": "Conversation not found"},
            )
        return Response(status_code=status.HTTP_204_NO_CONTENT)

    @app.api_route(
        "/v1/conversations/{conversation_id}/items",
        methods=["GET"],
    )
    async def conversations_v1_items(conversation_id: str) -> JSONResponse:
        items = conversation_store.list_items(conversation_id)
        if items is None:
            return JSONResponse(
                status_code=status.HTTP_404_NOT_FOUND,
                content={"detail": "Conversation not found"},
            )
        return JSONResponse(status_code=status.HTTP_200_OK, content={"data": items})

    @app.post("/v1/chat", response_model=ChatResponse)
    async def create_chat_execution(request: ChatRequest) -> ChatResponse:
        """Create a new chat execution with real workflow execution.

        This replaces the old /v1/responses endpoint with proper workflow integration.
        """
        import os
        from datetime import datetime

        # Generate execution ID
        execution_id = str(uuid4())

        # Create execution state
        state = ExecutionState(
            execution_id=execution_id,
            workflow_id=request.workflow_id,
            status=ExecutionStatus.PENDING,
            user_message=request.message,
            conversation_id=request.conversation_id,
            started_at=datetime.utcnow(),
            metadata=request.metadata,
        )

        # Save to Redis if available
        redis_client = get_redis_client() if _redis_client else None
        if redis_client:
            try:
                await redis_client.save_state(state)
            except Exception as e:
                LOGGER.warning(f"Failed to save state to Redis: {e}")

        # Start workflow execution in background
        # Store task reference to prevent garbage collection (RUF006)
        background_task = asyncio.create_task(  # noqa: F841, RUF006
            execute_workflow_background(execution_id, request.workflow_id, request.message)
        )

        # Build WebSocket URL
        base_url = os.getenv("BASE_URL", "ws://localhost:8000")
        if base_url.startswith("http://"):
            base_url = base_url.replace("http://", "ws://")
        elif base_url.startswith("https://"):
            base_url = base_url.replace("https://", "wss://")
        websocket_url = f"{base_url}/ws/chat/{execution_id}"

        return ChatResponse(
            execution_id=execution_id,
            status=ExecutionStatus.PENDING,
            websocket_url=websocket_url,
            message="Execution created successfully",
        )

    @app.get("/v1/chat/executions/{execution_id}")
    async def get_execution_status(execution_id: str) -> JSONResponse:
        """Get execution status and results."""
        redis_client = get_redis_client() if _redis_client else None

        if not redis_client:
            return JSONResponse(
                status_code=status.HTTP_503_SERVICE_UNAVAILABLE,
                content={"detail": "Redis not available"},
            )

        try:
            state = await redis_client.get_state(execution_id)
            if not state:
                return JSONResponse(
                    status_code=status.HTTP_404_NOT_FOUND,
                    content={"detail": "Execution not found"},
                )

            return JSONResponse(
                status_code=status.HTTP_200_OK,
                content=state.to_status_response().model_dump(),
            )
        except Exception as e:
            LOGGER.error(f"Failed to get execution status: {e}")
            return JSONResponse(
                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
                content={"detail": str(e)},
            )

    @app.websocket("/ws/chat/{execution_id}")
    async def websocket_chat(websocket: WebSocket, execution_id: str) -> None:
        """WebSocket endpoint for streaming workflow execution events."""
        ws_manager = get_websocket_manager()
        await ws_manager.connect(websocket, execution_id)

        try:
            # Keep connection alive and wait for events
            while True:
                # Wait for ping/pong or disconnect
                try:
                    await asyncio.wait_for(websocket.receive_text(), timeout=30.0)
                except TimeoutError:
                    # Send keepalive ping
                    await websocket.send_json({"type": "ping"})
                except Exception:
                    break
        except WebSocketDisconnect:
            ws_manager.disconnect(websocket, execution_id)
        except Exception as e:
            LOGGER.error(f"WebSocket error: {e}")
            ws_manager.disconnect(websocket, execution_id)

    async def execute_workflow_background(
        execution_id: str, workflow_id: str, user_message: str
    ) -> None:
        """Execute workflow in background and stream events via WebSocket.

        Args:
            execution_id: Unique execution ID
            workflow_id: Workflow to execute (magentic_fleet or collaboration)
            user_message: User's input message
        """
        redis_client = get_redis_client() if _redis_client else None
        ws_manager = get_websocket_manager()
        event_collector = EventCollector(execution_id)

        # Update status to running
        if redis_client:
            try:
                await redis_client.update_status(execution_id, ExecutionStatus.RUNNING)
            except Exception as e:
                LOGGER.warning(f"Failed to update status: {e}")

        try:
            # Get workflow factory
            factory = get_workflow_factory()

            # Create workflow from YAML (synchronous call)
            workflow = factory.create_from_yaml(workflow_id)

            # Start streaming task
            async def stream_events() -> None:
                while True:
                    event = await event_collector.get_event(timeout=1.0)
                    if event:
                        await ws_manager.send_json(event, execution_id)
                        if event["type"] in ("complete", "error"):
                            break

            stream_task = asyncio.create_task(stream_events())

            # Execute workflow with timeout (workflow.run is async)
            try:
                result = await asyncio.wait_for(
                    workflow.run(user_message, include_status_events=True), timeout=120.0
                )

                # Process workflow events from result
                from agent_framework import (
                    MagenticAgentDeltaEvent,
                    MagenticAgentMessageEvent,
                    MagenticFinalResultEvent,
                )

                for event in result:
                    if isinstance(event, MagenticAgentDeltaEvent):
                        event_collector.handle_agent_delta(event)
                    elif isinstance(event, MagenticAgentMessageEvent):
                        event_collector.handle_agent_message(event)
                    elif isinstance(event, MagenticFinalResultEvent):
                        event_collector.handle_final_result(event)
                        break  # Final event processed

                # Update state with completion
                if redis_client:
                    state = await redis_client.get_state(execution_id)
                    if state:
                        from datetime import datetime

                        state.status = ExecutionStatus.COMPLETED
                        state.completed_at = datetime.utcnow()
                        state.messages = event_collector.messages
                        await redis_client.save_state(state)

            except TimeoutError:
                if redis_client:
                    await redis_client.update_status(execution_id, ExecutionStatus.TIMEOUT)
                raise

            # Wait for streaming to complete
            await stream_task

        except Exception as e:
            LOGGER.error(f"Workflow execution failed: {e}")
            event_collector.handle_error(e)

            if redis_client:
                await redis_client.update_status(execution_id, ExecutionStatus.FAILED, str(e))

            # Send error event
            await ws_manager.send_json(
                {
                    "type": "error",
                    "execution_id": execution_id,
                    "data": {"error": str(e)},
                },
                execution_id,
            )

    # Keep old /v1/responses for backward compatibility (deprecated)
    @app.post("/v1/responses")
    async def responses_v1_legacy(request: Request) -> StreamingResponse:
        """Legacy endpoint - simple SSE emulation for tests.

        The tests expect a text/event-stream SSE response with a sequence of
        events: a workflow.event, streaming delta events, and a completion.
        We'll produce a deterministic small stream and also append to the
        in-memory conversation history so the tests can assert history entries.
        """
        try:
            payload = await request.json()
        except Exception:
            payload = {}

        # Extract conversation id and user content
        conversation_id = _extract_conversation_id(payload) or conversation_store.create()["id"]
        user_text = _extract_user_text(payload.get("input", payload))

        # Add user message to conversation history
        conversation_store.add_message(
            conversation_id, "user", content=[{"type": "input_text", "text": user_text or ""}]
        )

        async def event_stream() -> AsyncGenerator[bytes, None]:
            # workflow event
            yield _format_sse_event({"type": "workflow.event", "data": {"workflow": "legacy"}})
            await asyncio.sleep(0)

            # single delta output (combine pieces) and record assistant message
            combined = (
                "AgenticFleet â€” overview: manager + agents\n\n"
                "It supports dynamic spawning, checkpointing, and HITL approvals."
            )
            # append assistant reply to conversation history so frontend tests see it
            try:
                conversation_store.add_message(
                    conversation_id,
                    "assistant",
                    content=[{"type": "output_text", "text": combined}],
                )
            except Exception:
                # best-effort: ignore history failures in this minimal server
                LOGGER.exception("Failed to append assistant message to conversation history")

            yield _format_sse_event({"type": "response.output_text.delta", "text": combined})
            await asyncio.sleep(0)

            # completed event
            completed = {
                "type": "response.completed",
                "response": {"conversation_id": conversation_id},
            }
            yield _format_sse_event(completed)
            await asyncio.sleep(0)

            # final done marker
            yield b"data: [DONE]\n\n"

        from starlette.responses import StreamingResponse

        return StreamingResponse(event_stream(), media_type="text/event-stream")

    @app.post("/v1/approvals")
    async def create_approval_request(
        request: Request,
        db: Session = Depends(get_db),  # noqa: B008
    ) -> JSONResponse:
        data = await request.json()
        approval_request = ApprovalRequest(
            request_id=str(uuid4()),
            conversation_id=data.get("conversation_id"),
            details=data.get("details"),
        )
        db.add(approval_request)
        db.commit()
        db.refresh(approval_request)
        # Here you would emit an approval.requested SSE event
        # This is a placeholder for the actual SSE event emission
        print(f"SSE Event: approval.requested, request_id={approval_request.request_id}")
        return JSONResponse(
            status_code=status.HTTP_201_CREATED, content={"request_id": approval_request.request_id}
        )

    @app.get("/v1/approvals")
    async def list_pending_approvals(db: Session = Depends(get_db)) -> JSONResponse:  # noqa: B008
        pending_approvals = (
            db.query(ApprovalRequest).filter(ApprovalRequest.status == ApprovalStatus.PENDING).all()
        )
        return JSONResponse(
            status_code=status.HTTP_200_OK,
            content=[
                {"request_id": ar.request_id, "details": ar.details} for ar in pending_approvals
            ],
        )

    @app.post("/v1/approvals/{request_id}")
    async def respond_to_approval_request(
        request_id: str,
        response: ApprovalResponse,
        db: Session = Depends(get_db),  # noqa: B008
    ) -> JSONResponse:
        approval_request = (
            db.query(ApprovalRequest).filter(ApprovalRequest.request_id == request_id).first()
        )
        if not approval_request:
            return JSONResponse(
                status_code=status.HTTP_404_NOT_FOUND,
                content={"detail": "Approval request not found"},
            )

        if response.decision == "approved":
            approval_request.status = ApprovalStatus.APPROVED
        elif response.decision == "rejected":
            approval_request.status = ApprovalStatus.REJECTED
        else:
            return JSONResponse(
                status_code=status.HTTP_400_BAD_REQUEST, content={"detail": "Invalid decision"}
            )

        db.commit()
        # Here you would emit an approval.responded SSE event
        # This is a placeholder for the actual SSE event emission
        print(
            f"SSE Event: approval.responded, request_id={request_id}, status={approval_request.status}"
        )
        return JSONResponse(
            status_code=status.HTTP_200_OK, content={"status": approval_request.status}
        )

    @app.api_route("/v1/workflow/dynamic", methods=["POST"])
    async def workflow_dynamic_placeholder(_: Request) -> JSONResponse:
        return _not_implemented()

    # v2 API surface (Workflow Configuration) ----------

    @app.get("/v2/workflows")
    async def list_workflows(
        factory: WorkflowFactory = Depends(get_workflow_factory),  # noqa: B008
    ) -> JSONResponse:
        """List all available workflow configurations."""
        workflows = factory.list_available_workflows()
        return JSONResponse(
            status_code=status.HTTP_200_OK,
            content={"workflows": workflows},
        )

    @app.get("/v2/workflows/{workflow_id}")
    async def get_workflow_config(
        workflow_id: str,
        factory: WorkflowFactory = Depends(get_workflow_factory),  # noqa: B008
    ) -> JSONResponse:
        """Get configuration for a specific workflow."""
        try:
            config = factory.get_workflow_config(workflow_id)
            return JSONResponse(
                status_code=status.HTTP_200_OK,
                content=config.model_dump(),
            )
        except ValueError as exc:
            return JSONResponse(
                status_code=status.HTTP_404_NOT_FOUND,
                content={"detail": str(exc)},
            )

    @app.post("/v2/workflows/{workflow_id}/create")
    async def create_workflow_instance(
        workflow_id: str,
        factory: WorkflowFactory = Depends(get_workflow_factory),  # noqa: B008
    ) -> JSONResponse:
        """Create a workflow instance from configuration.

        This endpoint is a placeholder for future workflow instantiation.
        Currently returns workflow metadata without creating a live instance.
        """
        try:
            config = factory.get_workflow_config(workflow_id)
            # In the future, this would create an actual workflow instance
            # workflow = factory.create_from_yaml(workflow_id)
            return JSONResponse(
                status_code=status.HTTP_201_CREATED,
                content={
                    "workflow_id": workflow_id,
                    "name": config.name,
                    "status": "configuration_loaded",
                    "message": "Workflow instance creation not yet implemented",
                },
            )
        except ValueError as exc:
            return JSONResponse(
                status_code=status.HTTP_404_NOT_FOUND,
                content={"detail": str(exc)},
            )

    @app.api_route("/v1/{path:path}", methods=["GET", "POST", "PUT", "PATCH", "DELETE"])
    async def v1_fallback_placeholder(path: str, _: Request) -> JSONResponse:
        return _not_implemented()

    return app


app = create_app()
