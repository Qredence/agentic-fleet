# Required by Serena MCP server in .mcp.json - set to your local agentic-fleet repository path
PROJECT_PATH="/path/to/your/agentic-fleet"

# OpenAI (requires API key)
OPENAI_API_KEY="sk-..."
OPENAI_BASE_URL=""  # Optional: custom OpenAI endpoint (leave blank for default)
TAVILY_API_KEY="tvly-..."  # Tavily web search (required for researcher / web search tasks)
DSPY_COMPILE=true  # Enable DSPy supervisor compilation (set false to skip optimization phase)

# Azure OpenAI Configuration (takes precedence over standard OpenAI if both are set)
# When both AZURE_OPENAI_ENDPOINT and AZURE_OPENAI_API_KEY are set, the system will use
# Azure OpenAI Responses API format instead of standard OpenAI Chat Completions API.
AZURE_OPENAI_ENDPOINT="https://your-resource.openai.azure.com/"
AZURE_OPENAI_API_KEY="your-azure-openai-api-key"
AZURE_OPENAI_API_VERSION="preview"  # API version for Chat Completions API
# Alternative env var names (LiteLLM compatible)
# AZURE_API_BASE="https://your-resource.openai.azure.com/"
# AZURE_API_KEY="your-azure-openai-api-key"

# Azure AI Search Configuration
AZURE_SEARCH_ENDPOINT=your-azure-ai-search-endpoint
AZURE_SEARCH_KEY=your-azure-ai-search-key
AZURE_SEARCH_INDEX=your-index-name

# Azure OpenAI Deployed Model Names
AZURE_OPENAI_CHAT_COMPLETION_DEPLOYED_MODEL_NAME=your-chat-completion-model-name
AZURE_OPENAI_EMBEDDING_DEPLOYED_MODEL_NAME=your-embedding-model-name

# Azure Cosmos DB (optional - enables cloud history, memory, and self-improvement data)
AGENTICFLEET_USE_COSMOS=true
AZURE_COSMOS_ENDPOINT="https://your-account.documents.azure.com:443/"
# Provide either AZURE_COSMOS_KEY or configure managed identity credentials
AZURE_COSMOS_KEY="your-cosmos-key"
AZURE_COSMOS_DATABASE=agentic-fleet
AZURE_COSMOS_CONVERSATIONS_CONTAINER=conversations
AZURE_COSMOS_MESSAGES_CONTAINER=messages
AZURE_COSMOS_APPROVALS_CONTAINER=approvals
AZURE_COSMOS_WORKFLOW_RUNS_CONTAINER=workflowRuns
AZURE_COSMOS_AGENT_MEMORY_CONTAINER=agentMemory
AZURE_COSMOS_DSPY_EXAMPLES_CONTAINER=dspyExamples
AZURE_COSMOS_DSPY_OPTIMIZATION_RUNS_CONTAINER=dspyOptimizationRuns
AZURE_COSMOS_CACHE_CONTAINER=cache
AZURE_COSMOS_CONSISTENCY_LEVEL=Session
AZURE_COSMOS_THROUGHPUT=400
AZURE_COSMOS_MAX_RETRY_ATTEMPTS=5
AZURE_COSMOS_MAX_RETRY_WAIT_SECONDS=10
AZURE_COSMOS_AUTO_PROVISION=true
AZURE_COSMOS_USE_MANAGED_IDENTITY=false

# Observability (OpenTelemetry)
# Set ENABLE_OTEL=true when you have an OpenTelemetry collector running
ENABLE_OTEL=false
ENABLE_SENSITIVE_DATA=false
OTLP_ENDPOINT=http://localhost:4317
# Optional: Azure Application Insights
# APPLICATIONINSIGHTS_CONNECTION_STRING="InstrumentationKey=..."

# MCP Servers (optional)
# Chroma package search - get token from https://trychroma.com
CHROMA_TOKEN=

ENABLE_DSPY_AGENTS=true  # Enable DSPy agents (set false to disable)
# Langfuse Tracing (optional - enables LLM observability and tracing)
# Get your keys from https://cloud.langfuse.com â†’ Project Settings
LANGFUSE_PUBLIC_KEY="pk-lf-..."
LANGFUSE_SECRET_KEY="sk-lf-..."
LANGFUSE_BASE_URL="https://cloud.langfuse.com"  # EU region
# LANGFUSE_BASE_URL="https://us.cloud.langfuse.com"  # US region


LITELLM_API_KEY=
LITELLM_URL_OPENAI_COMPLETIONS="http://localhost:8080/v1/chat/completions"
LITELLM_URL_OPENAI_RESPONSES="http://localhost:8080/v1/openai/responses"
LITELLM_URL_OPENAI_EMBEDDINGS="http://localhost:8080/v1"
LITELLM_URL_ANTHROPIC_MESSAGES="http://localhost:8080/v1/anthropic/messages"
LITELLM_PROXY_URL=
