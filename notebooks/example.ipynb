{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e54be20b",
   "metadata": {},
   "source": [
    "# Azure Responses Client Direct Usage Example\n",
    "\n",
    "This notebook demonstrates direct `AzureResponsesClient` usage for structured response generation with Azure OpenAI models.\n",
    "\n",
    "**Features:**\n",
    "- Function calling capabilities with custom business logic\n",
    "- Structured output generation with Pydantic models\n",
    "- Streaming and non-streaming response modes\n",
    "\n",
    "**Prerequisites:**\n",
    "- Run `az login` in your terminal for Azure CLI authentication\n",
    "- Ensure your `.env` file has proper Azure OpenAI configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e464bfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) Microsoft. All rights reserved.\n",
    "\n",
    "# Import Required Libraries\n",
    "import os\n",
    "from random import randint\n",
    "from typing import Annotated\n",
    "\n",
    "from agent_framework.exceptions import ServiceResponseException\n",
    "from agent_framework.openai import OpenAIResponsesClient\n",
    "from azure.identity import AzureCliCredential\n",
    "from dotenv import load_dotenv\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "load_dotenv(override=True)\n",
    "\n",
    "REQUIRED_ENV_VARS = [\"AZURE_OPENAI_ENDPOINT\"]\n",
    "missing_env_vars = [var for var in REQUIRED_ENV_VARS if not os.environ.get(var)]\n",
    "if not os.environ.get(\"AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME\") and not os.environ.get(\n",
    "    \"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"\n",
    "):\n",
    "    missing_env_vars.append(\n",
    "        \"AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME or AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"\n",
    "    )\n",
    "if missing_env_vars:\n",
    "    raise OSError(\"Missing required environment variables: \" + \", \".join(missing_env_vars))\n",
    "\n",
    "AZURE_OPENAI_ENDPOINT = os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "AZURE_OPENAI_DEPLOYMENT = (\n",
    "    os.environ.get(\"AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME\")\n",
    "    or os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"]\n",
    ")\n",
    "\n",
    "\n",
    "def build_responses_client() -> OpenAIResponsesClient:\n",
    "    \"\"\"Create an Azure OpenAI Responses client using environment configuration.\"\"\"\n",
    "    return OpenAIResponsesClient(\n",
    "        credential=AzureCliCredential(),\n",
    "        endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "        deployment_name=\"gpt-5\",\n",
    "    )\n",
    "\n",
    "\n",
    "def handle_service_exception(context: str, exc: ServiceResponseException) -> None:\n",
    "    \"\"\"Provide actionable guidance when Azure OpenAI returns an error.\"\"\"\n",
    "    error_text = str(exc)\n",
    "    print(f\"{context} failed: {error_text}\")\n",
    "    if \"404\" in error_text:\n",
    "        print(\n",
    "            \"Hint: Verify that the deployment name exists in your Azure OpenAI resource \"\n",
    "            \"and that AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME (or chat fallback) matches it.\"\n",
    "        )\n",
    "    elif \"401\" in error_text:\n",
    "        print(\n",
    "            \"Hint: Authenticate with `az login` or provide a valid \"\n",
    "            \"AZURE_OPENAI_API_KEY / Azure credential.\"\n",
    "        )\n",
    "    elif \"429\" in error_text:\n",
    "        print(\n",
    "            \"Hint: The resource is rate limited. Consider reducing requests \"\n",
    "            \"or upgrading your quota.\"\n",
    "        )\n",
    "\n",
    "\n",
    "client = build_responses_client()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d497702",
   "metadata": {},
   "source": [
    "## Define Custom Tools\n",
    "\n",
    "Create a simple weather tool that the agent can call to get weather information for different locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2f0fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(\n",
    "    location: Annotated[str, Field(description=\"The location to get the weather for.\")],\n",
    ") -> str:\n",
    "    \"\"\"Get the weather for a given location.\"\"\"\n",
    "    conditions = [\"sunny\", \"cloudy\", \"rainy\", \"stormy\"]\n",
    "    return (\n",
    "        f\"The weather in {location} is {conditions[randint(0, 3)]} \"\n",
    "        f\"with a high of {randint(10, 30)}Â°C.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73d3e63",
   "metadata": {},
   "source": [
    "## Define Structured Output Format\n",
    "\n",
    "Use Pydantic models to define the expected structure of the agent's response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042e98a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputStruct(BaseModel):\n",
    "    \"\"\"Structured output for weather information.\"\"\"\n",
    "\n",
    "    location: str\n",
    "    weather: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dae798d6",
   "metadata": {},
   "source": [
    "## Initialize the Client and Get Response\n",
    "\n",
    "Create an Azure OpenAI Responses Client and query for weather information with structured output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02eeb8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the configuration being used for clarity\n",
    "print(f\"Configured endpoint: {AZURE_OPENAI_ENDPOINT}\")\n",
    "print(f\"Configured deployment: {AZURE_OPENAI_DEPLOYMENT}\")\n",
    "\n",
    "\n",
    "# Define the user message\n",
    "message = \"What's the weather in Amsterdam and in Paris?\"\n",
    "print(f\"User: {message}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccac89e0",
   "metadata": {},
   "source": [
    "## Option 1: Streaming Response\n",
    "\n",
    "Get a streaming response from the model, which provides real-time output as it's generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dc81e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure your .env file contains AZURE_OPENAI_ENDPOINT and either\n",
    "# AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME or\n",
    "# AZURE_OPENAI_CHAT_DEPLOYMENT_NAME with correct values\n",
    "try:\n",
    "    response: OpenAIResponsesClient = await client.create(\n",
    "        messages=[{\"role\": \"user\", \"content\": message}],\n",
    "    )\n",
    "    print(f\"Assistant: {response.content}\")\n",
    "except ServiceResponseException as exc:\n",
    "    handle_service_exception(\"Non-streaming creation\", exc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0015aea8",
   "metadata": {},
   "source": [
    "## Option 2: Non-Streaming Response\n",
    "\n",
    "Get a complete response in a single call without streaming."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710dfafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get non-streaming response\n",
    "try:\n",
    "    response = await client.get_response(message, tools=get_weather, response_format=OutputStruct)\n",
    "    print(f\"Assistant: {response.value}\")\n",
    "except ServiceResponseException as exc:\n",
    "    handle_service_exception(\"Non-streaming response\", exc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-fleet (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
