{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1186beb",
   "metadata": {},
   "source": [
    "# Magentic Orchestration Example\n",
    "\n",
    "This notebook demonstrates a complete Magentic workflow using Microsoft Agent Framework. The workflow coordinates two specialist agents:\n",
    "- **Researcher**: Finds information using web search\n",
    "- **Coder**: Executes Python code for analysis\n",
    "\n",
    "The example shows streaming callbacks, event handling, and complete workflow execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217891e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from agent_framework import (\n",
    "    ChatAgent,\n",
    "    HostedCodeInterpreterTool,\n",
    "    MagenticAgentDeltaEvent,\n",
    "    MagenticAgentMessageEvent,\n",
    "    MagenticBuilder,\n",
    "    MagenticCallbackEvent,\n",
    "    MagenticCallbackMode,\n",
    "    MagenticFinalResultEvent,\n",
    "    MagenticOrchestratorMessageEvent,\n",
    "    WorkflowOutputEvent,\n",
    ")\n",
    "from agent_framework.openai import OpenAIChatClient, OpenAIResponsesClient\n",
    "\n",
    "# Set OpenAI API key (ensure OPENAI_API_KEY is set in environment)\n",
    "if not os.getenv(\"OPENAI_API_KEY\"):\n",
    "    raise ValueError(\"Please set OPENAI_API_KEY environment variable\")\n",
    "\n",
    "print(\"\u2713 Imports loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0db7954",
   "metadata": {},
   "source": [
    "## Step 1: Configure Researcher Agent\n",
    "\n",
    "The ResearcherAgent specializes in finding information. It uses the `gpt-4o-search-preview` model to perform web searches.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b094c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "researcher_agent = ChatAgent(\n",
    "    name=\"ResearcherAgent\",\n",
    "    description=\"Specialist in research and information gathering\",\n",
    "    instructions=(\n",
    "        \"You are a Researcher. You find information without additional computation or quantitative analysis.\"\n",
    "    ),\n",
    "    chat_client=OpenAIChatClient(model_id=\"gpt-4o-search-preview\"),\n",
    ")\n",
    "\n",
    "\n",
    "print(\"\u2713 Researcher agent configured\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846d9952",
   "metadata": {},
   "source": [
    "## Step 2: Configure Coder Agent\n",
    "\n",
    "The CoderAgent writes and executes code using the hosted code interpreter tool.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d300f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "coder_agent = ChatAgent(\n",
    "    name=\"CoderAgent\",\n",
    "    description=\"A helpful assistant that writes and executes code to process and analyze data.\",\n",
    "    instructions=\"You solve questions using code. Please provide detailed analysis and computation process.\",\n",
    "    chat_client=OpenAIResponsesClient(model_id=\"gpt-4o\"),\n",
    "    tools=[HostedCodeInterpreterTool()],\n",
    ")\n",
    "\n",
    "print(\"\u2713 Coder agent configured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44f0486",
   "metadata": {},
   "source": [
    "## Step 3: Define Event Callback\n",
    "\n",
    "The callback processes workflow events including orchestrator messages, streaming deltas, agent messages, and final results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcabe8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# State for tracking streaming output\n",
    "\n",
    "last_stream_agent_id: str | None = None\n",
    "\n",
    "stream_line_open: bool = False\n",
    "\n",
    "\n",
    "async def on_event(event: MagenticCallbackEvent) -> None:\n",
    "    \"\"\"Process workflow events such as orchestrator messages, streaming deltas, agent messages, and final results.\n",
    "\n",
    "    \"\"\"\n",
    "    global last_stream_agent_id, stream_line_open\n",
    "\n",
    "    if isinstance(event, MagenticOrchestratorMessageEvent):\n",
    "        print(f\"\\n[ORCH:{event.kind}]\\n\\n{getattr(event.message, 'text', '')}\\n{'-' * 26}\")\n",
    "\n",
    "    elif isinstance(event, MagenticAgentDeltaEvent):\n",
    "        if last_stream_agent_id != event.agent_id or not stream_line_open:\n",
    "            if stream_line_open:\n",
    "                print()\n",
    "\n",
    "            print(f\"\\n[STREAM:{event.agent_id}]: \", end=\"\", flush=True)\n",
    "\n",
    "            last_stream_agent_id = event.agent_id\n",
    "\n",
    "            stream_line_open = True\n",
    "\n",
    "        print(event.text, end=\"\", flush=True)\n",
    "\n",
    "    elif isinstance(event, MagenticAgentMessageEvent):\n",
    "        if stream_line_open:\n",
    "            print(\" (final)\")\n",
    "\n",
    "            stream_line_open = False\n",
    "\n",
    "            print()\n",
    "\n",
    "        msg = event.message\n",
    "\n",
    "        if msg is not None:\n",
    "            response_text = (msg.text or \"\").replace(\"\\n\", \" \")\n",
    "\n",
    "            print(f\"\\n[AGENT:{event.agent_id}] {msg.role.value}\\n\\n{response_text}\\n{'-' * 26}\")\n",
    "\n",
    "    elif isinstance(event, MagenticFinalResultEvent):\n",
    "        print(\"\\n\" + \"=\" * 50)\n",
    "\n",
    "        print(\"FINAL RESULT:\")\n",
    "\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "        if event.message is not None:\n",
    "            print(event.message.text)\n",
    "\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "\n",
    "print(\"\u2713 Event callback defined\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fada32ea",
   "metadata": {},
   "source": [
    "## Step 4: Build Workflow\n",
    "\n",
    "Create the Magentic workflow with both agents and streaming callback support.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef65500",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Building Magentic workflow...\")\n",
    "\n",
    "workflow = (\n",
    "    MagenticBuilder()\n",
    "    .participants(researcher=researcher_agent, coder=coder_agent)\n",
    "    .on_event(on_event, mode=MagenticCallbackMode.STREAMING)\n",
    "    .with_standard_manager(\n",
    "        chat_client=OpenAIResponsesClient(model_id=\"gpt-4o\"),\n",
    "        max_round_count=10,\n",
    "        max_stall_count=3,\n",
    "        max_reset_count=2,\n",
    "    )\n",
    "    .build()\n",
    ")\n",
    "\n",
    "print(\"\u2713 Workflow built successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a96b48",
   "metadata": {},
   "source": [
    "## Step 5: Define Task\n",
    "\n",
    "Specify the research task comparing energy efficiency and CO2 emissions of different ML model architectures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6b32cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = (\n",
    "    \"I am preparing a report on the energy efficiency of different machine learning model architectures. \"\n",
    "    \"Compare the estimated training and inference energy consumption of ResNet-50, BERT-base, and GPT-2 \"\n",
    "    \"on standard datasets (e.g., ImageNet for ResNet, GLUE for BERT, WebText for GPT-2). \"\n",
    "    \"Then, estimate the CO2 emissions associated with each, assuming training on an Azure Standard_NC6s_v3 \"\n",
    "    \"VM for 24 hours. Provide tables for clarity, and recommend the most energy-efficient model \"\n",
    "    \"per task type (image classification, text classification, and text generation).\"\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"\u2713 Task defined: {task[:100]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84f501a2",
   "metadata": {},
   "source": [
    "## Step 6: Execute Workflow\n",
    "\n",
    "Run the workflow and stream the results. This requires valid OpenAI credentials.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185bb6ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_workflow():\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "\n",
    "    print(\"Starting workflow execution...\")\n",
    "\n",
    "    print(\"=\" * 50 + \"\\n\")\n",
    "\n",
    "    try:\n",
    "        output: str | None = None\n",
    "\n",
    "        async for event in workflow.run_stream(task):\n",
    "            # Events are processed by the on_event callback\n",
    "\n",
    "            if isinstance(event, WorkflowOutputEvent):\n",
    "                output = str(event.data)\n",
    "\n",
    "        if output is not None:\n",
    "            print(f\"\\n\\nWorkflow completed with result:\\n\\n{output}\")\n",
    "\n",
    "        else:\n",
    "            print(\"\\n\\nWorkflow completed (no output)\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"\\n\\nWorkflow execution failed: {e}\")\n",
    "\n",
    "        raise\n",
    "\n",
    "\n",
    "# Execute the workflow\n",
    "\n",
    "await run_workflow()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-fleet (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
