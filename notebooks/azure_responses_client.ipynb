{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d07aac0",
   "metadata": {},
   "source": [
    "# Azure Responses Client Direct Usage Example\n",
    "\n",
    "**Copyright (c) Microsoft. All rights reserved.**\n",
    "\n",
    "Demonstrates direct `AzureOpenAIResponsesClient` usage for structured response generation with Azure OpenAI models.\n",
    "Shows function calling capabilities with custom business logic.\n",
    "\n",
    "## Features Demonstrated\n",
    "- Direct Azure OpenAI Responses API usage\n",
    "- Function calling with custom tools\n",
    "- Structured output using Pydantic models\n",
    "- Streaming and non-streaming responses\n",
    "- Azure CLI credential authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0b907d5",
   "metadata": {},
   "source": [
    "## Setup and Imports\n",
    "\n",
    "Import required libraries for Azure OpenAI integration, function calling, and structured outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a755ba6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from typing import Annotated\n",
    "\n",
    "from agent_framework import ChatResponse\n",
    "from agent_framework.azure import AzureOpenAIResponsesClient\n",
    "from azure.identity import AzureCliCredential\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77bf1fa",
   "metadata": {},
   "source": [
    "## Define Custom Tools\n",
    "\n",
    "Create a function that will be called by the model to get weather information.\n",
    "The function uses type annotations for automatic schema generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccf5e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather(\n",
    "    location: Annotated[str, Field(description=\"The location to get the weather for.\")],\n",
    ") -> str:\n",
    "    \"\"\"Get the weather for a given location.\"\"\"\n",
    "    conditions = [\"sunny\", \"cloudy\", \"rainy\", \"stormy\"]\n",
    "    return f\"The weather in {location} is {conditions[randint(0, 3)]} with a high of {randint(10, 30)}Â°C.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365f6f6f",
   "metadata": {},
   "source": [
    "## Define Output Structure\n",
    "\n",
    "Create a Pydantic model to enforce structured output format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9035bc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OutputStruct(BaseModel):\n",
    "    \"\"\"Structured output for weather information.\"\"\"\n",
    "\n",
    "    location: str\n",
    "    weather: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2152b9dc",
   "metadata": {},
   "source": [
    "## Initialize Azure OpenAI Client\n",
    "\n",
    "Create the client using Azure CLI credentials. Make sure you've run `az login` before executing this cell.\n",
    "\n",
    "**Note:** You can replace `AzureCliCredential` with other authentication options like `DefaultAzureCredential`, `ManagedIdentityCredential`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066d875e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Azure OpenAI Responses Client\n",
    "client = AzureOpenAIResponsesClient(credential=AzureCliCredential())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910e41d7",
   "metadata": {},
   "source": [
    "## Example 1: Streaming Response\n",
    "\n",
    "Get a streaming response with function calling and structured output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a67faa23",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def streaming_example():\n",
    "    message = \"What's the weather in Amsterdam and in Paris?\"\n",
    "    print(f\"User: {message}\\n\")\n",
    "\n",
    "    response = await ChatResponse.from_chat_response_generator(\n",
    "        client.get_streaming_response(message, tools=get_weather, response_format=OutputStruct),\n",
    "        output_format_type=OutputStruct,\n",
    "    )\n",
    "\n",
    "    print(f\"Assistant: {response.value}\")\n",
    "    return response\n",
    "\n",
    "\n",
    "# Run the streaming example\n",
    "streaming_response = await streaming_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "338abab9",
   "metadata": {},
   "source": [
    "## Example 2: Non-Streaming Response\n",
    "\n",
    "Get a non-streaming response with the same capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb8ba28",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def non_streaming_example():\n",
    "    message = \"What's the weather in Amsterdam and in Paris?\"\n",
    "    print(f\"User: {message}\\n\")\n",
    "\n",
    "    response = await client.get_response(message, tools=get_weather, response_format=OutputStruct)\n",
    "\n",
    "    print(f\"Assistant: {response.value}\")\n",
    "    return response\n",
    "\n",
    "\n",
    "# Run the non-streaming example\n",
    "non_streaming_response = await non_streaming_example()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9894253",
   "metadata": {},
   "source": [
    "## Inspect Response Structure\n",
    "\n",
    "Examine the structured output returned by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffcc407",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect the response value (Pydantic model)\n",
    "print(\"Response type:\", type(non_streaming_response.value))\n",
    "print(\"Response data:\", non_streaming_response.value.model_dump_json(indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2e3e66",
   "metadata": {},
   "source": [
    "## Complete Example Function\n",
    "\n",
    "A complete example combining all the concepts above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83451ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def main(stream: bool = True) -> None:\n",
    "    \"\"\"\n",
    "    Main function demonstrating Azure OpenAI Responses Client usage.\n",
    "\n",
    "    Args:\n",
    "        stream: Whether to use streaming responses (default: True)\n",
    "    \"\"\"\n",
    "    # Initialize client\n",
    "    client = AzureOpenAIResponsesClient(credential=AzureCliCredential())\n",
    "\n",
    "    message = \"What's the weather in Amsterdam and in Paris?\"\n",
    "    print(f\"User: {message}\\n\")\n",
    "\n",
    "    if stream:\n",
    "        print(\"[Using streaming response]\\n\")\n",
    "        response = await ChatResponse.from_chat_response_generator(\n",
    "            client.get_streaming_response(message, tools=get_weather, response_format=OutputStruct),\n",
    "            output_format_type=OutputStruct,\n",
    "        )\n",
    "    else:\n",
    "        print(\"[Using non-streaming response]\\n\")\n",
    "        response = await client.get_response(\n",
    "            message, tools=get_weather, response_format=OutputStruct\n",
    "        )\n",
    "\n",
    "    print(f\"Assistant: {response.value}\")\n",
    "    return response\n",
    "\n",
    "\n",
    "# Run with streaming\n",
    "result = await main(stream=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745503f7",
   "metadata": {},
   "source": [
    "## Try Different Queries\n",
    "\n",
    "Experiment with different weather queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2169d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def query_weather(location: str):\n",
    "    \"\"\"Query weather for a specific location.\"\"\"\n",
    "    client = AzureOpenAIResponsesClient(credential=AzureCliCredential())\n",
    "    message = f\"What's the weather in {location}?\"\n",
    "    print(f\"User: {message}\\n\")\n",
    "\n",
    "    response = await client.get_response(message, tools=get_weather, response_format=OutputStruct)\n",
    "    print(f\"Assistant: {response.value}\\n\")\n",
    "    return response\n",
    "\n",
    "\n",
    "# Try different locations\n",
    "await query_weather(\"London\")\n",
    "await query_weather(\"Tokyo\")\n",
    "await query_weather(\"New York\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "061a548e",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Direct Azure OpenAI Responses Client usage** - No agent framework required for simple scenarios\n",
    "2. **Function calling** - Custom tools with automatic schema generation from type hints\n",
    "3. **Structured outputs** - Pydantic models for reliable response parsing\n",
    "4. **Streaming and non-streaming** - Both modes supported with same API\n",
    "5. **Azure authentication** - Using Azure CLI credentials (extensible to other methods)\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Explore more complex function calling scenarios\n",
    "- Add multiple tools and let the model decide which to use\n",
    "- Integrate with the full AgenticFleet orchestration system\n",
    "- Add error handling and retry logic for production use"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agentic-fleet (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
